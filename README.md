# rnn_bible
A simple Recurrent/transformer Neural Network trained on the bible using word-level prediction in numpy
## ğŸ“Œ Features 
    - Word-level RNN/Transformer built from scratch
    - Trained on the full King James Bible
    - NumPy-only implementation â€” no PyTorch or TensorFlow
    -  In the future add RLHF
## ğŸ§  Motivation

This project explores the foundations of sequence modeling and deep learning by implementing an RNN on a real-world text corpus from scratch. It serves as a learning tool for understanding backpropagation through time (BPTT), training loops, and neural text generation. And, follow my medium account for explanations on the code teaching you how to implement your own over engineered LLM. Medium: [https://medium.com/@jvelasco20081](https://jadenvv.medium.com/)

## Setup 
run ```pip install -r requirements.txt```
to train the model run ```python3.12 train.py``

## ğŸ™ Acknowledgements
    


